# Diagrammatic intensities: modelling methods in digital humanities

## abstract
This paper concerns that part of the digital humanities that makes use of data analytic techniques that go by the names 'data mining', 'machine learning' or 'pattern recognition.'
These techniques, while not exactly new and in many cases of long-standing provenance, animate and drive many of the most prominent data-intensive digital humanities projects. 
Following C.S. Peirce and F. Guattari, we can identify a diagrammatic component of the digital humanities. 
The diagrammatic takes several different semiotic forms in data analytic techniques: the data plot (histogram, scatterplot, line plot, network plot, etc.); the algebraic expression (the probability distribution; the error function, etc.) and the algorithm (sometimes expressed in pseudo-code, but more often than not in code written in `R`, `Python` or suchlike). 
These diagrams are at the heart of many different data-intensive knowledge enterprises (social media, predictive medicine, financial trading, government security, etc.), but in the digital humanities they come to bear on large collections of documents (literature) and images (photographs and videos). 
The diagrams are little discussed in their own right, even though they deeply animate many of the practices associated with the digital humanities.
Until we find ways of intensifying thinking around diagrammatic processes, digital humanities remains captive to the coding processes of existing abstract machines. 
The paper will suggest, through some discussion of diagrams relating to Principal Component Analysis, Latent Dirichlet Allocation and Naive Bayes how diagrammatic processes might intensify through  machine learning.

## ideas

- quotes from Foucault and Deleuze on statements as regularity -- the curve -- and the line between the visible and sayable -- this line is generative of truth. But that line, a sight of slippage is precisely not being investigated in DH.

## Introduction

How is knowledge produced today? Explicitly, or implicitly, it increasingly relies on a certain kind of model or algorithmic procedure that I shall simply refer to as machine learning. Whether in the marketing, in business analytics, in computational social science, in social physics or in digital humanities, the marks of machine learning are written everywhere. 

The film _Her_ presents this work in terms of desire and prediction. [SCREEN CLIP]. I find it interesting to see this film less in terms of the machine learning that the advanced operating system undertakes than in the relationship between the main character, Theo, a writer of soulful letters, and the algorithms. If we don't fall in love with the models (as Theo, the _belle lettrist_ does), how do we relate to the models? This paper is an attempt to address that relationship.

## Relating to the models -- from social physics to digital humanities via sociology

While statistical modelling has long been an integral part of many social sciences, the nature of statistical modelling has shifted in the last decade or so. It is now a constitutive part of 'new' fields such as social physics, computational social science and digital humanities. There are striking commonalities between these fields in terms of their modelling practices. Moreover, each of these fields offers an account of how we should relate to the models they use. 

To give a brief sense of what that relation might look like, we could turn to social scientists writing about 'big data.' Viktor Mayer-Schönberger and Kenneth Cukier describe the implications of having a lot more data. They  write that:

> Just as the Internet radically changed the world by adding communications to computers, so too will big data change fundamental aspects of life by giving it a quantitative dimension it never had before. [@Mayer-Schonberger_2013, 12]

> One of the areas that being most dramatically shaken up by N = all is the social sciences. They have lost their monopoly on making sense of empirical social data, as big-data analysis replaces the highly skilled survey specialists of the past. ... More important, the need to sample disappears [@Mayer-Schonberger_2013, 30].

The first point here is fairly familiar data talk. The availability of much data is allowing new practices of quantification to appear. I suppose for social scientists the striking claim here is that this quantification is a fundamental change, and that it is unprecedented. (One might turn to the history of statistics and quantification to check that claim, but I leave that aside). The broader implication is that quantification will mean that knowledge of life, social life  I think they mean here, will not be the province of social scientists. The fundamental change partly concerns who will give life the quantitative dimension. This change reverberates in the second quote which suggests that the technical expertise of social scientists in making sense of life using relatively specialized instruments and limited amounts of data is being eroded by the availability of data. Despite the gravity of these shifts, Mayer-Schönberger and Cukier provide little account of how 'big-data analysis' will actually work. They say 'it's about applying math to huge quantities of data in order to infer probabilities' (12). Which is fine as far as it goes, but doesn't offer much to social scientists who might want to participate in any such changes.

A more emphatic version of the relation to modelling comes from the Alex 'Sandy' Pentland. In his recent book on social physics, Pentland calls for a dialogue between 'our human intuition and the big data statistics':

> With the arrival of dense, continuous data and modern computation, we can now map out the details of society and build mathematical models of them. But these raw mathematical models are very far beyond most humans' understandings. They have too many variables and the relationships are too complex for the poor human mind. [@Pentland_2014, 188]

This is somewhat alarming in a different way. Rather than saying we need to infer probabilities, Pentland suggests that these models are 'very far beyond most humans' understandings.' The news is not all bad, as Pentland goes on to suggest a dialogue:

> There needs to be a dialogue between our human intuition and the big data statistics, something that is not built into most of our management systems today. ... A new language, one that goes beyond markets and classes and captures how detailed connections between people determine change will help us develop this understanding [@Pentland_2014, 189]

I'm not going much further here with Pentland's 'new language' that goes beyond 'markets' [economics?] and 'classes' (sociology?), other than to point out that it will still have to grapple with the problem of 'raw mathematical models.' Even in Pentland's terms, that seems inescapable.  

Does recent work in the digital humanities offer anything better? Some recent work in algorithmic criticism [@Ramsay_2011] in literature and macroanalysis in history [@Jockers_2013] might offer a different lead. In _Macroanalysis: Digital Methods and Literary History_, Matthew Jockers describes he we might relate to one currently popular machine learning or statistical modelling technique, the topic model:

>   If the statistics are rather too complex to summarize here, I think it is fair to skip the mathematics and focus on the end results. We needn't know how long and hard Joyce sweated over _Ulysses_ to appreciate his genius, and a clear understanding of the LDA machine is not required in order to see the beauty of the result. [@Jockers_2013, 124]

The widely used topic models or Latent Dirichlet Allocation models provide a litmus test of how the relation to these machine learning techniques more generally is taking shape. I won't discuss them in any detail here, but only note that again we see the familiar observations about the complexity of the models, and the imperative to focus on 'the beauty of the result'.

Yet I feel quite ambivalent about the somewhat misaligned analogy between statistical modelling and Joyce. What is at stake, I will suggest, in relating to the models is not a question of how long and difficult they are to understand. Nor it is a question of a new language of modelling that matches human intuitions to raw mathematical models, nor finally is it a matter of generally accepting that all modelling is inference of probabilities, as if saying that solves all problems. The issue here, rather, is that the models start to matter a lot more when there are multiple attempts to model more or less the same patterns of social life coming from quite different directions, or conversely, where a common set of  modelling approaches suddenly proliferates and mobilizes across a previously disparate set of domains. While science and technology studies (STS) has long taken an interest in the life of abstractions such as mathematics, measurements or models, it rarely had to deal with a situation where its own objects of research  were themselves explicitly claiming to be knowledges of the social. In other words, STS didn't really have to care about the models directly. It didn't need to countenance the possibility that it would use the models. But, explicitly or implicitly, this is the situation social scientists face now. We have a much more vital interest in these models to the extent that they operate to produce valorized knowledge and sometimes scientific knowledge of the social. 

In other words, I think we need to have a much more direct relation to these models in order to both understand how they perform the social -- we have known for quite a long time now that the social is somewhat performatively constituted -- and in order to gauge where we stand in the configuration of knowledge-making practices that are taking shape in the form of things like machine learning. Put even more directly, I would say this: we cannot make sense of what is happening in the many shifts in modelling practice associated with machine learning unless we have a way of understanding how models move. The question then is how we would intensify our relation to the models? 

## Reading machine learning diagrammatically 

The _Ulysses_ of the literature on machine learning would perhaps be _Elements of Statistical Learning_. So the remainder of this paper addresses the problem of how to read this book. Somewhat ironically, reading the literature  machine learning poses many of the same problems that the proponents of algorithmic criticism, distant reading or macroanalysis point to in their own fields of literary history.  Amidst this avalanching mass, a  single highly cited and compendious textbook, _Elements of Statistical Learning: Data Mining, Inference, and Prediction_ [@Hastie_2009], currently in its second edition, can be seen from almost any point of the terrain.[^12] The authors of the book, Jeff Hastie, Rob Tibshirani and Jerome Friedman are statisticians working at Stanford and Columbia University. (Statisticians and computer scientists from Stanford University loom large in the world of machine learning, perhaps due to their proximity to Silicon Valley.)  In terms of scientific publications, this book is like the Death Star in the _Stars Wars_ film series. It is a  massive orbiting object, densely bristling with diagrams, equations, tables, algorithms,  graphs and references to other scientific literature. Like the online machine learning courses and programming books I discuss below, _ESL_  combines statistical techniques with various algorithms to 'learn from data' [@Hastie_2009, 1]. The 768 pages of this often tersely written and quite mathematical book range across various kinds of problems (identifying spam email, predicting risk of heart disease, recognising handwritten digits, etc.), and various machine learning techniques, methods and algorithms (linear regression, k-nearest neighbours, neural networks, support vector machines, the Google Page Rank algorithm, etc.). This is not the only juggernaut machine learning texts.  I could just have well cleaved to Alpaydin's _Introduction to Machine Learning_ [@Alpaydin_2010]  (a more computer science-base account), to Christopher Bishop's  heavily mathematical _Pattern recognition and machine learning_ [@Bishop_2006], Brian Ripley's luminously illustrated and almost coffee-table formatted _Pattern Recognition and Neural Networks_ [@Ripley_1996], Tom Mitchell's  earlier artificial intelligence-centred _Machine learning_ [@Mitchell_1997], Peter Flach's  perspicuous _Machine Learning: The Art and Science of Algorithms that Make Sense of Data_ [@Flach_2012], or further afield, the sobering and laconic _Statistical Learning for Biomedical Data_ [@Malley_2011].  These and quite a few other recent machine learning textbooks display a range of emphases, ranging from the highly theoretical to the very practical, from an orientation to statistical inference to an emphasis on computational processes, from  science to commercial applications. 

The book attracts different styles of reading. It is often cited by academic machine learning practitioners as an authoritative guide. On the other hand, students participating in new data science courses often come from different disciplinary backgrounds and find the tome unhelpful (see the comment by students in [@Schutt_2013]). Whether the citations are friendly or not, Google Scholar reports over 20,00 citations of the book http://scholar.google.com/scholar?hl=en&q=elements+of+statistical+machine+learning, October 2014), a huge citation count by any standards. (Michel Foucault's _The History of Sexuality: an Introduction_, one of the most highly cited book in the humanities,  receives about the same number of citations.) The citations that [@Hastie_2009] as well as its previous edition [@Hastie_2001] receive do not arrive principally from machine learning researchers. They come from a wide variety of fields.[^13] It is hard to find a field of contemporary science, engineering, health and indeed social science that has not cited it. 

It is a difficult book to read, not just because 768 pages is a lot to read, but because the semiotic machinery of the book generates vectors and orbital trajectories that veer and peel off in many different directions. The Death Star aspect of the book, its somewhat forbidding presence in the literature, comes from the vast semiotic weave of equations, diagrams, tables, algorithms, bibliographic apparatus, and numbers wreathed in sheer typographic luxuriance. The weave of these elements far exceeds almost anything found in the humanities or social sciences, and, almost before anything else, prompts attention to the question of who or what reads. For instance, in terms of outgoing references, _ESL_ webs together a field of scientific and technical work with data and predictive models ranging across half a century. The reference list beginning at page 699 [@Hastie_2009, 699] runs for around 35 pages, and the five hundred or so references there point in many directions. One could learn a lot from that reference list, which itself spans biomedical, engineering, telecommunications, ecology, operations research and many other fields. 

The book is a bit like an oriental carpet in its patterning. Beginning from almost the first pages proper of the book, almost every page has a figure or a table or a formal algorithm (counting these together: equations = 968; figures = 291; tables = 34 and algorithms = 94 giving a total of almost 1400 operational devices threaded through the book). As we have already seen, around `r equation_count` equations rivet the text into mathematical abstractions of varying sophistication, and construct an semiotic machinery of considerable sophistication and connectivity. The anthropologist Alfred Gell suggests that how we look at an oriental carpet depends on whether we own it or not [@Gell_1993]. I'm not suggesting that we should own _ESL_ like a carpet, but it does seem to me that we need to shift some of the relations of possession that currently run through the dense semiotic tangle of the its pages. The form of possession or ownership we might develop in relating to such texts pivot on the way we handle the most numerous graphic forms we find there: the equations.

## The mathematical glint of machine learning

While references come and go from many different places (and take too many forms for me to fully understand or explain here) into _ESL_ they are all framed by a notion of learning based on predictive models. The predictive model is like the Death Star's planetary destroying laser: all energy feeds the predictive model.  Perhaps this weaponised metaphor is a little misleading (and risky, since I'm not suggesting that Hastie, Tibshirani and Friedman are Sith), but there is one line of alignment between the laser and the predictive models in _ESL_: cutting sharp, straight lines through opaque clouds of data-matter is what much machine learning seeks to do. It manoeuvres in complex ways in drawing these lines (as we will see), but lines cutting, cleaving, and shattering things are very much the working edge of machine learning.  The predictive models in _ESL_ are  dominated by a single prediction technique, linear regression models or fitting a line to points. Jeff Hastie, Rob Tibshirani and Jerome Friedman, the authors, definitely advocate a statistical legacy and inheritance in machine learning:

>The linear model has been a mainstay of statistics for the past 30 years and remains one of our most important tools. Given a vector of inputs
$X^T = (X_1 , X_2, . . . , X_p)$, we predict the output $Y$ via the model
>$$\hat{Y} = \hat{\beta_0}  + \sum^p_(j=1)X_j\hat{\beta_j)}$$
>The term $\hat{\beta_0}$ is the intercept, also known as the _bias_ in machine learning [@Hastie_2009, 11].

In the course of the book, linear regression is subjected to countless variations, iterations, expansions and modifications. Their own research spans several decades and a range of topics concerning linear regression models and their variations ('ridge regression'; 'least angle regression'; etc.). But this introduction of the 'mainstay of statistics,' the linear model, already introduces a harsh form -- the mathematical equation -- that is perhaps the most prominent feature in the text. Any reading of the book has to work out a way to traverse theose forms. 

\begin {equation}
\label {eq:linear_model}
\hat{Y} = \hat{\beta_0}  + \sum^p_{j=1} X_j \hat{\beta_j}
\end {equation}

In its relatively compressed typographic weave, expressions such as \ref{eq:linear_model} operationalize movements through data that we will attend to closely. These expressions, which are not comfortable reading by large for non-technical readers, are however worth looking at carefully as diagrams. They can be found in hundreds in [@Hastie_2009], but also in many other places. While their presence distinguishes machine learning from many other domains of computer science where mathematical equations are much less common, these equations also allow the book to collate and borrow from a panoply of scientific publications  and datasets in fields of statistics, artificial intelligence and computer science. Along with the citations, the graphical plots, the algorithms (implemented in code described below), these equations are integral connective tissue in machine learning. Unless we come to grips with their diagram force, without succumbing to the obscuring dazzle of mathematical signs, the connectivity and mobility of these forms will be lost on us.

I find it useful here to follow Charles Sanders Peirce account of mathematics in terms of diagrams. 'Mathematical reasoning,' he writes, 'is diagrammatic' [@Peirce_1998b, 206]. That it, we should see mathematics, whether it takes an algebraic or geometrical form, whether it appears in symbols, letters, lines or curves as  diagrams. Now for Peirce, a diagram is a kind of 'icon.' The icon is a sign that resembles the object it refers to: it has a relation of likeness. What likeness appears in \ref{eq:linear_model}? As Peirce says, 'many diagrams resemble their objects not all in their looks; it is only in respect to the relations of their parts that their likeness consists' [@Peirce_1998b, 13]. They are, in short, icons of relation. As we will soon see, \ref{eq:linear_model} could be expressed in statements in a programming language like `Python` or `R`, or in algorithmic pseudo-code, or perhaps most accessibly, as graphic figure (a line drawn through a cloud of points). In none of these associated diagrams can the relations between the parts be observed in the same way as they in the algebraic form. The 'very idea of the art' as Peirce puts it [@Peirce_1992a, 228] of algebraic expressions is that the formulae can be manipulated. The graphic form of the expression include the various classical Greek symbols such as $\sum$ or $\prod$, as well as the letters $x, y, z$ and the indices (indexical signs) that appear in subscript or superscript, as well as the spatial arrangement of all these in lines and sometimes arrays. A variety of relations run between these different symbols and spatial arrangements. For instance, in all such expressions, the difference between the left hand side of the '=' and the right hand side is very important. By convention, the left hand side of the expression is the value that is predicted or calculated (the 'response' variable) and the right hand side are the input variables or 'features' that contribute data to the model or algorithm. This spatial arrangement fundamentally affects the design of algorithms. In the case of \ref{eq:linear_model}, the '^' over $\hat{Y}$ symbolises a predicted value rather than a value that can be known completely through deduction, derivation or calculation. This distinction between predicted and actual values organizes a panoply of different practices and imperatives (for instance, to investigate the disparities between the predicted and actual values -- machine learning practitioners spend a lot of time on that problem).  The general point is that the whole formulae is a diagram, or an icon that '*exhibits*, by means of the algebraical signs (which are not themselves icons), the relations of the quantities concerned' [@Peirce_1998b, 13]. Because such diagrams suppress so many details, they allow one to focus on a more limited range of relations between parts. The manipulation of those relations generates new diagrams or patterns. This affordance of diagrammatic forms is extremely important in the intensification of machine learning. Importantly, diagrams can diagram other diagrams. Put differently, operations can be themselves the subject of operations. Or functions can themselves for functions of functions. This nesting and coiled aspect of the diagrams is highly generative since it allows what Peirce calls 'transformations' [@Peirce_1998b, 212] or the construction of 'a new general predicate'[@Peirce_1992a, 303].[^22]  The intensive processing of data today via predictive models is largely channelled via such diagrams. These diagrams are not conspicuous in the infrastructures, and they are not directly felt or perceived by people or things they impinge upon.

While I  seek to see the equations as diagrams, and I do persist in looking at them and will present a selection of them (nowhere near as many as found in _ESL_), the equations can you leave you feeling that you don't quite understand. Peirce advises not to begin with examples that are too simple. ('In simple cases, the essential features are often so nearly obliterated that they can only be discerned when one knows what to look for' [@Peirce_1998b, 206].) He also suggests 'it is of great importance to return again and again to certain features' [@Peirce_1998b, 206]. That is helpful in reducing the perplexity that these diagrammatic expressions tend to engender if you are not used to them. The price of looking at these diagrammatic expressions repeatedly is well worth paying if in consequence we can understand something of how the transformations, generalisations or intensification of the diagrammatizing flows across disciplinary boundaries, across social stratifications, and sometimes, generate potentially different ways of thinking about collectives, inclusion and belonging.  


## Diagrammatic forms as places to return to

The question is: how would we return to the diagrams or icons of relations? I think we might have to give a different answer to the one that Peirce could have given, and a different one to what might be suggested by an initial reading  of _ESL_. The point is that these diagrams are not simply looked at. They are written and re-written in ever-widening spirals.

If we were to follow Peirce's injunction to 'return again and again to certain features,' how would we do that?  _ESL_ is a difficult book. The cost of its diagrammatic density (equations, citations, tables, datasets, plots) is a certain feeling of 'not quite understanding' for many readers. This is partly because the book largely traverses finished work, and partly because it covers so much terrain. Professor Andrew Ng's course 'Machine Learning' CS229 at Stanford (http://cs229.stanford.edu/) might provide a supplementary path into machine learning [@Ng_2008].[^61] Note that Ng is a computer scientist, not a statistician. The course description runs as follows:

>This course provides a broad introduction to machine learning and statistical pattern recognition. Topics include supervised learning, unsupervised learning, learning theory, reinforcement       learning and adaptive control.   Recent applications of machine learning, such as to robotic control, data mining, autonomous navigation, bioinformatics, speech recognition, and text and       web data processing are also discussed [@Ng_2008]

CS229 is in many ways a  typical computer science pedagogical exposition of machine learning.  Machine learning expositions  usually begin with simple datasets and the simplest possible statistical models and machine learning algorithms, and then, with a greater or lesser degree of attention to issues of implementation, move through a succession of increasingly sophisticated and specialised techniques.  This pattern is found in many of the how-to books, in the online courses, and in the academic textbooks, including [@Hastie_2009]. The strikingly distinctive difference  of  Ng's CS229 lectures from almost all other expository materials is that we see someone writing.  Line after line of equations using chalk on a blackboard. Occasionally, questions come from students in the audience (not shown on the Youtube videos), but mostly that transcription of equations from paper to blackboard continues uninterrupted.[^23]

[Figure from Ng]

In a time when PowerPoint presentations or some other electronic textuality would very much have been the norm (2007), why is a Stanford computer science professor, teaching a fairly advanced postgraduate course, writing on a chalkboard by hand? The Figure shows a brief portion of around 100 pages of notes I made on this course. The act of writing down these equations and copying the many hand-drawn graphs Ng produced was a deliberative descriptive experiment, but more importantly an exercise in 'returning again and again' to what is perhaps overly hardened in  _ESL_.  Like the 50,000 or so other people who had watched this video, I complied with Ng's injunction to 'copy it, write it out, cover it, and see if you can reproduce it' [@NgAndrew_2008].  While it occasions much writing and drawing, and many struggles to keep up with the diagrams that Ng narrates as he writes, it seems to me that this writing of equations, with all their substitutions and derivations, alongside the graphic sketches of intuitions about the machine learning techniques, adds something that is quite hard to finesse in _ESL_. There the diagrammatic weave between the expressions of linear algebra, calculus, statistics, and the algorithms is almost too tight to work with. In Ng's CS229 lectures, by contrast, the weave is much more open. In a longer version of this paper, I would go on to describe what it means to learn to  draw these diagrammatic equations by hand. The important point is that even in this one page we can begin to see something about the diagrams -- they often connect to each other through diagonal movements, movements that move symbols laterally, and movements that jump between the equation diagrams and the graphic diagrams. Both forms of diagonal movement bring with them transformations. 


## The diagonal dance of diagrams

But even that description of learning to draw the diagrams or icons of relations, and to do the manipulations that link together much of the vast selection of tools comprising machine learning would not capture many of the diagrammatic movements associated with _ESL_. I am suggesting, then, that we should follow the transformations of diagrams associated with machine learning beyond their manual manipulation in reading and writing. Following Peirce, we might begin to see machine learning as a diagrammatic practice in which different forms of diagram are constantly connected, substituted, embedded or created from existing diagrams.

The diagrams we have already seen from _ESL_ - algebraic formulae and network topology - don't exhaust the variations at all. Just a brief glance through this book or almost any other in the field shows not only many formulae, but tables, matrices, arrays, line graphs, contour plots, scatter plots,  dendrograms and trees, as well as algorithms expressed as pseudo-code. The connections between these diagrams are not always very tight or close. Learning to machine learning (whether you are a human learner or a learner in the sense of a machine) means a diagonalizing dancing between diagrams. This dance is relatively silent and sometimes almost motionless as signs slide between different diagrammatic articulations. Diagrammatization offers then a way to track the ongoing project which tries treat data like farmers treat crops (see epigraph from Domingos in this chapter).  To understand what machines can learn, we need to look at how they have been drawn, designed, or formalised. But what in this work of designing and formalising predictive models is like farming? Some very divergent trajectories open up here. On the one hand, the diagrams become machines when they are implemented. On the other hand, the machines generate new diagrams when they function. We need to countenance both forms of movement in order to understand any of the preceding diagrams -- the algebraic expressions or the diagrams of models such as the perceptron or its descendants, the neural network.  This means going downstream from the textbooks into actual implementations and places where people, algorithms, and machines mingle more than they do in the relatively neat formality of the textbooks. 

One line of movement in this diagrammatic dance runs from what we might called formal diagrams to statistical algorithmic diagrams. The point is that on each page of _ESL_  we are seeing, reading, puzzling over and perhaps learning from the products of code execution. The figures are all produced by code. The tables are mostly produced by code. The algorithms specify how to implement code, and the equations diagram the various operations, spaces and movements that run through the algorithms. But in the 700 pages of the book we don't see a single line of code. That means we are seeing diagrams somewhat removed from the practice of machine learning, which all takes place in code. We need, I would suggest, to see how the formal diagrams of the predictive models are diagrammed in actual machines. 

## A machine learning praxiography? Re-implementing statistical methods in `R`

What would we learn by studying the proliferation of implementations of artificial intelligence or machine learning algorithms rather than their history or the controversies associated with them? Science studies scholars such as Anne-Marie Mol urged the need to keep practice together with theories of what exists. Towards the beginning of _The Body Multiple: Ontology in Medical Practice_ [@Mol_2003], Mol writes:

> If it is not removed from the practices that sustain it, reality is multiple. This may be read as a description that beautifully fits the facts. But attending to the multiplicity of reality is also an act. It is something that may be done – or left undone [@Mol_2003, 6]

Mol's work offers a cogent case for developing accounts of what is real steeped in the practices that make it real. While similar sounding affirmations of the underpinning role of practice can be found in many parts of social sciences and humanities (since who would not affirm the centrality of practice?), Mol's insistence on this nexus of practice or doing and the existence of things in their plurality offers another way forward in reading _Elements of Statistical Learning_.  Tracking techniques -- a crystallised form of practice -- and the flow of their implementations is a way of keeping practices in their multiplicity. Describing machine learning in terms of practices could be an act that attends to their multiplicity. Mol's coins the term  *praxiography*, a variant on ethnography, to refer to an act of describing practice in the name of preserving their multiple-making value. This term has particular resonance for work with data, which is itself always heavily entwined in writing and reading practices. The practice, I have been suggesting, is principally diagrammatic. Could we praxiographically attend to data and machine learning in terms of diagrams?

On this point, programming languages and snippets of code present some useful threads to follow. Nearly all of the examples in _The Elements of Statistical Learning_ are implemented in  a single programming language, `R`. While no `R` code appears in the book, a single of line opens the book to a different kind of diagrammatic reading:  

```{r elem_stat_learn_install, echo=TRUE}
 install.packages('ElemStatLearn', dependencies='Suggests', repos = 'http://cran.us.r-project.org')
```

This line of code affords some other ways of reading the book and the diagonally extended practice running through it a bit more deeply. There is nothing too opaque, I would suggest, about the line of code itself, but there are some folds and convolutions associated with it that open fresh perspectives. Take the part of the line `dependencies = 'Suggests'`. When the line of code executes, this stipulation of `dependencies` leads to a quite wide-ranging installation event. If the installation works (and that assumes quite a lot of configuration and installation work has already taken place; for instance, installing a recent version of the `R` platform), then the book is now augmented by various pieces of code, and by various datasets.

The single line of code shown above installs `ElemStatLearn`, a `R` programming language package [@Halvorsen_2012], as well its 'dependencies' from a software repository located at http://cran.us.r-project.org. The domains and sub-domains of the URL bear closer examination. A .org domain suggests something outside commerce, education, or government. The proper name 'r-project' suggests that this organisation is involved in an ongoing process, a project not a product or a service. The 'us,' which stands for USA, connotes geography and nations, but implies by its forward position in the URL that nation is not the prime consideration, and that there might be other nations ('uk', 'tw', 'au', 'de') somehow present.  

## Ideas into code

Programming and writing code for data analysis has widely supplanted the use of statistical software applications, at least in statistical research. Writing code has always been  central in machine learning where algorithms are the primary expressive forms that ideas take as they become diagrams. Finally, the two of the main proponents of `R` and `S` describe the motivation for the language:

> The goal of the S language ... is "to turn ideas into software, quickly and faithfully" ... it is the duty of the responsible data analysts to engage in this process ... the exercise of drafting an algorithm to the level of precision that programming requires can in itself clarify ideas and promote rigorous intellectual scrutiny. ... Turning ideas into software in this way need not be an unpleasant duty. [@Venables_2000, 2]

Bill Venables and Brian Ripley, statisticians working on developing `S`, the almost identical commercial predecessor to `R`,   wrote in the early 1990s of  the responsibility of data analysts to write not just use software.   They write 'software' here not in the sense of a product, but in the sense that today would more likely be called 'code.' This sense of coding and programming as clarifying and concretising ideas with precision has thoroughly taken hold in contemporary data analysis.

## Conclusion

I have been suggesting that we might intensify relations to machine learning by developing ways of reading key texts more diagrammatically. Diagrammatic practice is not purely visual, although it does involve forms of visibility (the equations, the plots, the typographic weave of bold face, Greek capital letters, subscripts and superscripts, and the implicit operations of multiplication and explicit mathematical operations of summation, exponentiation, etc.). Peirce's relatively straightforward account of the diagram as icons of relations, his injunction to return to the diagrams often, and advice not to start too simply all resonate with the kinds of diagrams woven through _Elements of Statistical Learning_. The most salient feature of the diagrams read diagrammatically is what we might term a kind of diagonalization running through and connecting the hundreds of equations scattered across the pages of the book. The diagonals connect key terms such as $\hat{\beta}$, $\mathbf{X}$ and $\hat{Y}$. These diagonals run through literature, not just this book, and many transformations, forms of compression, and ramification can be read from them. I have suggested the importance of following these diagonals in order to see how they intersect with tangentially touch practices, worlds and lives. 

The diagonalization of the diagrams of machine learning cannot be confined to the pages of _Elements of Statistical Learning_. The equations that lie at the heart of the predictive models overflow into algorithms, lines of code, code libraries, packages and implementations that anamorphically pull figures in certain directions not others. The lambent pages of the book derive from a historically tangled weave of techniques, places and knowledges. They literally arise in many ways from bodies of code in movement as we began to see in discussing the `ElemStatLearn` package and the 'Comprehensive R Archive Network.' The diagrammatic processes of the `R` language and its thousands of packages, as well as all the ancillary infrastructures, implementations, centralisations and devolutions of code sometimes figure very little in the formal diagrams of machine learning textbooks. They matter greatly in the diagonalization of those diagrams in the world. They begin to network the techniques, and the techniques or models begin to comprehend the world through them. 

Together these two forms of diagonalization (and more will appear in later chapters) begin to suggest that we are not confronted with either raw mathematics of humiliating complexity, or laborious complexity that need not concern us or deflect us from the beauty of results. Nor finally, do we see here, in the pages of _Elements of Statistical Learning_ and in work done with  `ElemStatLearn` anything that can be simply summarised as inferring probabilities. None of these formulations to my mind captures the diagrammatic intensity that could explain the proliferation of machine learning driven processes in all their variety (a variety that I do not enumerate here). Nor do they open a space in which one might describe practices in the way advocated by Mol when she describes description as an intervention. A diagrammatic account of  machine learning might just allow some new different diagonalizations to occur. Just as Hastie, Tibshirani and Friedman could only produce _Elements of Statistical Learning_ via many detours through `R`, our relationship with machine learning is likely to involve detours through code, through platforms, libraries. But the question is whether our movement through those diagrams will be linear replications, faithful readings of the canon. Or whether something more like the g


